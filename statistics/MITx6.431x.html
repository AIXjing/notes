<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Probability - The Science of Uncertainty and Data - Note</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../favicon.svg">
        
        
        <link rel="shortcut icon" href="../favicon.png">
        
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        
        <link rel="stylesheet" href="../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../chapter_1.html"><strong aria-hidden="true">1.</strong> Chapter 1</a></li><li class="chapter-item expanded "><a href="../git.html"><strong aria-hidden="true">2.</strong> Git</a></li><li class="chapter-item expanded "><a href="../tips.html"><strong aria-hidden="true">3.</strong> Visit with the Client &amp; Setup Overview</a></li><li class="chapter-item expanded "><a href="../frontend/frontend.html"><strong aria-hidden="true">4.</strong> Frontend</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../frontend/vue3.html"><strong aria-hidden="true">4.1.</strong> Vue3 note</a></li><li class="chapter-item expanded "><a href="../frontend/css.html"><strong aria-hidden="true">4.2.</strong> CSS</a></li></ol></li><li class="chapter-item expanded "><a href="../sql/sql.html"><strong aria-hidden="true">5.</strong> SQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../sql/duke.html"><strong aria-hidden="true">5.1.</strong> Duke-coursera</a></li></ol></li><li class="chapter-item expanded "><a href="../python/python.html"><strong aria-hidden="true">6.</strong> Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../python/Coursera-Michigan.html"><strong aria-hidden="true">6.1.</strong> Python-coursera-Michigan</a></li><li class="chapter-item expanded "><a href="../python/leanningfrommis.html"><strong aria-hidden="true">6.2.</strong> Learning in a hard way</a></li></ol></li><li class="chapter-item expanded "><a href="../statistics/statistics.html"><strong aria-hidden="true">7.</strong> Statistics rewind</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../statistics/MITx6.431x.html" class="active"><strong aria-hidden="true">7.1.</strong> Probability - The Science of Uncertainty and Data</a></li><li class="chapter-item expanded "><a href="../statistics/statinfer.html"><strong aria-hidden="true">7.2.</strong> Improve your statistical inferences</a></li><li class="chapter-item expanded "><a href="../statistics/inferentialstat.html"><strong aria-hidden="true">7.3.</strong> Inferential Statistics</a></li><li class="chapter-item expanded "><a href="../statistics/python.html"><strong aria-hidden="true">7.4.</strong> Statistics with Python</a></li><li class="chapter-item expanded "><a href="../statistics/problems.html"><strong aria-hidden="true">7.5.</strong> Common problems</a></li></ol></li><li class="chapter-item expanded "><a href="../dataviztools/dataviztools.html"><strong aria-hidden="true">8.</strong> Data Viz</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../dataviztools/projects.html"><strong aria-hidden="true">8.1.</strong> Dataviz Projects</a></li></ol></li><li class="chapter-item expanded "><a href="../english/english.html"><strong aria-hidden="true">9.</strong> English</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../english/speaking.html"><strong aria-hidden="true">9.1.</strong> Speaking English</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Note</h1>

                    <div class="right-buttons">
                        
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#probability---the-science-of-uncertainty-and-data-2021" id="probability---the-science-of-uncertainty-and-data-2021">Probability - The Science of Uncertainty and Data (2021)</a></h1>
<p>Use the course to re-build my statistics knowledge.</p>
<p><a href="https://www.edx.org/course/probability-the-science-of-uncertainty-and-data">The course link</a></p>
<p><a href="https://ece307.cankaya.edu.tr/uploads/files/introduction%20to%20probability%20(bertsekas,%202nd,%202008).pdf">The Book</a></p>
<h2><a class="header" href="#1-sample-space-and-probability" id="1-sample-space-and-probability">1 Sample Space and Probability</a></h2>
<h3><a class="header" href="#11-sample-space---a-set-of-outcomes" id="11-sample-space---a-set-of-outcomes">1.1 Sample space - A set of outcomes</a></h3>
<ul>
<li>
<p>discrete/finite example</p>
</li>
<li>
<p>continuous example</p>
</li>
</ul>
<h3><a class="header" href="#12-probability-axioms" id="12-probability-axioms">1.2 Probability Axioms</a></h3>
<ul>
<li>
<p>Nonnegativity
\(P(A) \geq 0 \)</p>
</li>
<li>
<p>Normalization
\( P( \Omega ) = 1 \), \(\Omega \) is the entire sample space.</p>
</li>
<li>
<p>(finite) Additivity: A and B are disjoint, then the probability of their unions satisfies \(P(A \cup B) = P(A) + P(B)\) (to be strengthened later)</p>
</li>
</ul>
<h4><a class="header" href="#121-simple-consequences-of-the-axioms" id="121-simple-consequences-of-the-axioms">1.2.1 Simple consequences of the axioms</a></h4>
<ol>
<li>
<p>For a sampe space consist of a finite number of disjointed events,
\[ 
P({s_1, s_2, ...., s_n}) = P(s_1) + P(s_2) + ...... P(s_n)
\]</p>
</li>
<li>
<p>\(A \subset B\), then \(P(A) \leq P(B)\)</p>
</li>
<li>
<p>\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</p>
</li>
<li>
<p>\(P(A \cup B) \leq P(A) + P(B))\)</p>
</li>
</ol>
<h3><a class="header" href="#13-probability-calculations" id="13-probability-calculations">1.3 Probability calculations</a></h3>
<h4><a class="header" href="#131-uniform-probability-law" id="131-uniform-probability-law">1.3.1 Uniform Probability Law</a></h4>
<ul>
<li>
<p>Discrete example</p>
<p>If the sample space consists of n possible outcomes which are equally likely (i.e., all single-element events have the same probability),
\[ 
P(A) = \frac{\text{number of elements of A}}{n}
\]</p>
</li>
<li>
<p>continuous example</p>
<p>probability = area</p>
</li>
</ul>
<h4><a class="header" href="#132-discrete-but-infinite-sample-space" id="132-discrete-but-infinite-sample-space">1.3.2 Discrete but infinite sample space</a></h4>
<ul>
<li>
<p>Sample space: {1, 2, 3 ....}</p>
<p>Given \(P(n) = \frac{1}{2^n}\), n = 1, 2, 3....</p>
<p>As \( P(\Omega) = 1 \): \(\frac{1}{2} + \frac{1}{4} + ....=  \sum\limits_{n=1}^\infty \frac{1}{2^n} = \frac{1}{2}\sum\limits_{n=0}^\infty \frac{1}{2^n} = \frac{1}{2}\frac{1}{1-1/2} = 1\) </p>
</li>
</ul>
<h4><a class="header" href="#133-countable-aditivity-axiom" id="133-countable-aditivity-axiom">1.3.3 Countable aditivity axiom</a></h4>
<p><em>Additivity holds only for &quot;<strong>countable</strong>&quot; sequences of events</em></p>
<p>If \(A_1, A_2, A_3 ...\) is an \(\underline{\text{infinite sequence of disjoined events}}\),</p>
<p>\[
P(A_1 \cup A_2 ......) = P(A_1) + P(A_2) + ......
\]</p>
<br>
<h3><a class="header" href="#14-mathematical-background" id="14-mathematical-background">1.4 Mathematical background</a></h3>
<h4><a class="header" href="#141-sets---a-collection-of-distinc-elements" id="141-sets---a-collection-of-distinc-elements">1.4.1 Sets - A collection of distinc elements</a></h4>
<ul>
<li>
<p>finite: e.g. {a, b, c, d}</p>
</li>
<li>
<p>infinite: the reals (R)</p>
</li>
<li>
<p>\( \Omega \) - the universal set</p>
</li>
<li>
<p>Ø - empty set</p>
</li>
</ul>
<p><em>What are reals?</em></p>
<p><em>The reals include rational numbers (terminating decimals and non-terminating recurring decimals and irrational numbers (non-terminating non-reccuring decimals</em></p>
<h4><a class="header" href="#142-unions-and-intersection" id="142-unions-and-intersection">1.4.2 Unions and intersection</a></h4>
<h4><a class="header" href="#143-de-morgans-law" id="143-de-morgans-law">1.4.3 De Morgans' Law</a></h4>
<ul>
<li>
<p>\( (S \cap T)^c = S^c \cup T^c \) and \( (S \cup T)^c = S^c \cap T^c \)</p>
</li>
<li>
<p>\( (S^c \cap T^c)^c = S \cup T \)</p>
</li>
</ul>
<h4><a class="header" href="#144-other-important-mathematical-backgrounds" id="144-other-important-mathematical-backgrounds">1.4.4 Other important mathematical backgrounds</a></h4>
<ul>
<li>
<p>Sequences and their limits </p>
<p><em>squence: an enumerated collection of objects</em></p>
</li>
<li>
<p>When does a sequence converge</p>
<ul>
<li>
<p>if \(a_i \leq a_{i+1}\)</p>
<ul>
<li>
<p>the sequence &quot;converge to \(\infty\)&quot;</p>
</li>
<li>
<p>the sequence converge to some real number a </p>
</li>
</ul>
</li>
<li>
<p>if \(|a_i - a| \leq b\), for \(b_i \to 0\), then \(a_i \to a\)</p>
</li>
</ul>
</li>
<li>
<p>Infinite series</p>
<p><em>series(infinte sums) vs. summation(finite sums)</em></p>
<p>\(\sum\limits_{n=1}^\infty a_i = \lim\limits_{n\to\infty}\sum\limits_{i=1}^n a_i\) </p>
<ul>
<li>
<p>\(a_i \leq 0\): limit exists</p>
</li>
<li>
<p>if term \(a_i\) do not all have the same sign:</p>
<p>a. limit does not exist</p>
<p>b. limit may exist but be different if we sum in a different order</p>
<p>c. <strong>Fact</strong>: limit exists and independent of order of summation if  \(\sum\limits_{n=1}^\infty |a_i| \leq \infty\) </p>
</li>
</ul>
</li>
<li>
<p>Geometric series (等比数列、等比级数)</p>
<p>\(\sum\limits_{i=0}^\infty a^i = 1 + a + a^2 + ...... = \frac{1}{1-a} \text{           |a| &lt; 1} \)</p>
</li>
</ul>
<h3><a class="header" href="#14-sets" id="14-sets">1.4 Sets</a></h3>
<h4><a class="header" href="#141-countable-and-uncountable-infinite-sets" id="141-countable-and-uncountable-infinite-sets">1.4.1 Countable and uncountable infinite sets</a></h4>
<ul>
<li>
<p>Countable</p>
<ul>
<li>
<p>integers, pairs of positive integers, etc.</p>
</li>
<li>
<p>rational numbers q (有理数), with 0 &lt; q &lt; 1</p>
</li>
</ul>
</li>
<li>
<p>Uncountable - <em>continuous numbers</em></p>
<ul>
<li>
<p>the interval [0, 1]</p>
</li>
<li>
<p>the reals, the plane, etc.</p>
</li>
</ul>
<p><em>How to prove the reals are uncountable - &quot;Control's diagonalization argument&quot;</em></p>
</li>
</ul>
<br>
<h2><a class="header" href="#unit-2-conditioning-and-independence" id="unit-2-conditioning-and-independence">Unit 2 Conditioning and independence</a></h2>
<p>Refer to Section 1.3 - 1.5 in the textbook</p>
<h3><a class="header" href="#21-conditional-and-bayes-rules" id="21-conditional-and-bayes-rules">2.1 Conditional and Bayes' Rules</a></h3>
<h4><a class="header" href="#211-the-definition-of-conditional-probability" id="211-the-definition-of-conditional-probability">2.1.1 The definition of conditional probability</a></h4>
<p>P(A|B) = &quot;probability of A, given that B occurred&quot;</p>
<p>\[
P(A|B) = \frac{P(A \cap B )}{P(B)}
\]</p>
<p>defined only when P(B) &gt; 0</p>
<h4><a class="header" href="#212-conditional-probabilities-share-properties-of-ordinary-probabilities" id="212-conditional-probabilities-share-properties-of-ordinary-probabilities">2.1.2 Conditional probabilities share properties of ordinary probabilities</a></h4>
<ul>
<li>
<p>\(P(A|B) \geq 0\)</p>
</li>
<li>
<p>\(P(\Omega|B) = 1\)</p>
</li>
<li>
<p>\(P(B|B) &lt; 0\)</p>
</li>
<li>
<p>If \(A \cap C = Ø\), then \(P(A \cup C|B) = P(A|B) + P(C|B)\) also only applies to countable and finite sequence (countable additivity axioms).</p>
</li>
</ul>
<h4><a class="header" href="#213-models-base-on-conditional-probabilities" id="213-models-base-on-conditional-probabilities">2.1.3 Models base on conditional probabilities</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/117574884-993c6600-b0df-11eb-9125-c5501b77d001.png" alt="image" /></p>
<p><strong>1. The multiplication rule</strong></p>
<pre><code>\\(P(A \cap B) = P(B)P(A|B) = P(A)P(B|A)\\)

\\(P(A^c \cap B \cap C^c) = P(A^c \cap B) P(C^c|A^c \cap B) = P(A^c) P(B|A^c) P(C^c|A^c \cap B)\\)

\\(P(A_1 \cap A_2...\cap A_n) = P(A_1) \prod\limits_{i=2}^n P(A_i|A_1 \cap A_2...\cap A_i)\\)
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41487483/118396328-55051480-b64f-11eb-9c9e-9703528df69e.png" alt="image" /></p>
<p><strong>2. Total probability theorem</strong></p>
<p><img src="https://user-images.githubusercontent.com/41487483/118396377-9e556400-b64f-11eb-8e1a-f5530bb63fd3.png" alt="image" /></p>
<p><strong>3. Bayes' rules</strong></p>
<p><img src="https://user-images.githubusercontent.com/41487483/118396464-eeccc180-b64f-11eb-9080-e7e86ad223bf.png" alt="image" /></p>
<h3><a class="header" href="#22-independence" id="22-independence">2.2 Independence</a></h3>
<h4><a class="header" href="#221-conditional-independence" id="221-conditional-independence">2.2.1 Conditional independence</a></h4>
<p>Independent of two events</p>
<ul>
<li>
<p>Intuitive &quot;definition&quot;: P(B|A) = P(B) </p>
<ul>
<li>Occurence of A provides no new information about B</li>
</ul>
</li>
</ul>
<p>Definition of independence:</p>
<p>\(P(A \cap B) = P(A) \times P(B)\)</p>
<p><em>whether two events disjoined or joined is not associated with independence</em></p>
<p><strong>Independent of events complements</strong></p>
<p>If A and B are independent, then A and \(B^c\) are independent. </p>
<p><strong>Independent of events complements</strong></p>
<p><img src="https://user-images.githubusercontent.com/41487483/118397139-df9b4300-b652-11eb-9e1c-e8b293e070fc.png" alt="image" /></p>
<p><strong>Conditioning may affect independence</strong></p>
<p><img src="https://user-images.githubusercontent.com/41487483/118397436-35241f80-b654-11eb-89cf-d6eacefd924e.png" alt="image" /></p>
<h4><a class="header" href="#222-independence-of-a-collection-of-events" id="222-independence-of-a-collection-of-events">2.2.2 Independence of a collection of events</a></h4>
<ul>
<li>
<p>Intuitive &quot;definition&quot;: Information on some of the events does not change probabilities related to the remaining events</p>
</li>
<li>
<p>Definition: Events \(A_1, A_2,....., A_n\) are called independent if: </p>
<p>\(P(A_i \cap A_j \cap .... \cap A_m) = P(A_i)P(A_j)...P(A_m)\)</p>
</li>
</ul>
<p><strong>Pairwise independence</strong></p>
<p>n = 3:</p>
<p>\(P(A_1 \cap A_2) = P(A_1)P(A_2)\)</p>
<p>\(P(A_1 \cap A_3) = P(A_1)P(A_3)\)</p>
<p>\(P(A_2 \cap A_3) = P(A_2)P(A_3)\)</p>
<p>vs. 3-way indenpendence</p>
<p>\(P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)\)</p>
<p><strong>Independence vs. pairwise independence</strong></p>
<p><img src="https://user-images.githubusercontent.com/41487483/118398068-4d496e00-b657-11eb-91d3-ade5aa82f245.png" alt="image" /></p>
<h4><a class="header" href="#223-reliability" id="223-reliability">2.2.3 Reliability</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/118398123-7bc74900-b657-11eb-8f00-9313ffc249f6.png" alt="image" /></p>
<h2><a class="header" href="#unit-3-couting" id="unit-3-couting">Unit 3 Couting</a></h2>
<h3><a class="header" href="#31-basic-counting-principle" id="31-basic-counting-principle">3.1 Basic counting principle</a></h3>
<p>r stages and \(n_i\) choices at stage i give the total number of possible choices \( n_1 * n_2 * ....n_r \)</p>
<h3><a class="header" href="#32-permutation" id="32-permutation">3.2 Permutation</a></h3>
<ul>
<li><strong>Permutation</strong> - number of ways of ordering n elements (repetition is prohibited)</li>
</ul>
<p>\[n * (n-1) * (n-2) * ... * 2 * 1 = n!\]</p>
<ul>
<li>Number of subsets of {1, 2, ...n} = \(2^n\)</li>
</ul>
<h3><a class="header" href="#33-combinations" id="33-combinations">3.3 Combinations</a></h3>
<ul>
<li>
<p><strong>combinations</strong> \(\binom{n}{k}\)- number of <em>k</em>-element subsets of a given <em>n</em>-element set</p>
<p><em>How is combination equation derived?</em></p>
<p>Two ways of constructing an <strong>ordered</strong> sequence of <em>k</em> <strong>distinct</strong> items:</p>
<ul>
<li>
<p>choose the <em>k</em> items one at a time: </p>
<p>\[
n (n-1) ... (n-k+1) = \frac{n!}{k!(n-k)!}
\]</p>
</li>
<li>
<p>choose <em>k</em> items, then order them:</p>
<p>\[
\left(
\begin{array}{c}
n \\
k
\end{array}
\right)k!
\]</p>
</li>
</ul>
<p>There we have 
\[
\left(
\begin{array}{c}
n \\
k
\end{array}
\right) = \frac{n!}{k!(n-k)!}
\]</p>
</li>
</ul>
<h3><a class="header" href="#33-binominal-coeffficient" id="33-binominal-coeffficient">3.3 Binominal coeffficient</a></h3>
<ul>
<li>
<p><strong>Binominal coeffficient</strong> \(\binom{n}{k}\) - Binomial probabilities</p>
<p>Toss coins n times and each toss is given independent, P(Head) = p</p>
<p>\[
P(\text{k heads}) = \binom{n}{k}p^k (1-p)^{n-k}
\]</p>
<p>If asking P(k heads without ordered), then </p>
<p>\[
P(\text{k heads}) = p^k (1-p)^{n-k}
\]</p>
<p>Therefore, \(\binom{n}{k}\) is the number of <em>k</em>-head sequence</p>
</li>
</ul>
<h3><a class="header" href="#34-partitions" id="34-partitions">3.4 Partitions</a></h3>
<p><img src="https://user-images.githubusercontent.com/41487483/119098744-73d02600-ba16-11eb-8406-20acdf555e25.png" alt="image" /></p>
<ul>
<li>
<p><strong>multinomial coeffecient</strong> (number of partitions) =</p>
<p>\[
\frac{n!}{n_1! n_2! ... n_r!}
\]</p>
</li>
</ul>
<p>If r = 2, then \(n_1 = k\) and \(n_2 = n - k\). There is \(\frac{n!}{n! (n-k)!}\) which is \(\binom{n}{k}\)</p>
<ul>
<li>A simple example</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/119102618-83516e00-ba1a-11eb-86e6-b87e6ecf3467.png" alt="image" /></p>
<p><img src="https://user-images.githubusercontent.com/41487483/119102964-e8a55f00-ba1a-11eb-9693-d29eb512ac3f.png" alt="image" /></p>
<h2><a class="header" href="#4-discrete-random-variables" id="4-discrete-random-variables">4 Discrete random variables</a></h2>
<h3><a class="header" href="#41-probability-mass-function-pmf" id="41-probability-mass-function-pmf">4.1 Probability mass function (PMF)</a></h3>
<p><strong>Random variable</strong>(r.v.): a function from the sample space to the real numbers, notated as X.</p>
<p><strong>PMF</strong>: probability distribution of X </p>
<p>\[
p_X(x) = P(X = x) = P({w \in \Omega, s.t. X(\omega) = x})
\]</p>
<h3><a class="header" href="#42-discrete-random-variable-examples" id="42-discrete-random-variable-examples">4.2 Discrete Random variable examples</a></h3>
<h4><a class="header" href="#421-bernoulli-random-variables" id="421-bernoulli-random-variables">4.2.1 Bernoulli random variables</a></h4>
<p>with parameter \(p \in [0,1]\)</p>
<p>\[
p_X(x) = \begin{cases} 1, p(x) = p \\ 0, p(x) = 1 - p \end{cases} 
\]</p>
<ul>
<li>
<p>Models a trial that results in either success/failure, Heads/Tails, etc.</p>
</li>
<li>
<p><strong>Indicator random variables</strong> of an event A, \(I_A\) iff A occurs</p>
</li>
</ul>
<h4><a class="header" href="#422-uniform-random-variables" id="422-uniform-random-variables">4.2.2 Uniform random variables</a></h4>
<p>with paramters a,b</p>
<ul>
<li>
<p>Experiment: pick one of a, a+1 .... b at a random; all equally likely</p>
</li>
<li>
<p>Sample space; {a, a + 1, .... b}</p>
</li>
<li>
<p>Random variables X: \(X(\omega) = \omega\)</p>
</li>
</ul>
<h4><a class="header" href="#423-binomial-random-variables" id="423-binomial-random-variables">4.2.3 Binomial random variables</a></h4>
<p>with parameters: pasitive integer \(n; p \in [0,1]\)</p>
<ul>
<li>
<p>Experiment: n independent toses of a coin with P(Heads) = p</p>
</li>
<li>
<p>Sample space: set of sequences of H and T of length n</p>
</li>
<li>
<p>Random variables X: number of Heads observed</p>
</li>
<li>
<p>Model of: number of successes in a given number of independent trials </p>
</li>
</ul>
<p>\[
p_X(k) = \left(\begin{array}{c} n \\ k \end{array}  \right)p^k(1-p)^{n-k}, k = 0, 1 ..., n
\]</p>
<h4><a class="header" href="#424-geometric-random-variables" id="424-geometric-random-variables">4.2.4 Geometric random variables</a></h4>
<p>with parameter p: 0 &lt; p ≤ 1</p>
<ul>
<li>
<p>Experiment: infinitely many independent tosses of a coin: P(Heads) = p</p>
</li>
<li>
<p>Random variable X: number of tosses until the first Heads</p>
</li>
<li>
<p>Model of waiting times; number of tirals until a success</p>
</li>
</ul>
<p>\[
p_X(k) = P(X = k) = P(T...TH) =(1-p)^{k-1}p, k = 1,2,3...<br />
\]</p>
<h3><a class="header" href="#43-expectationmean-of-a-random-variable" id="43-expectationmean-of-a-random-variable">4.3 Expectation/mean of a random variable</a></h3>
<ul>
<li>
<p><strong>Definition</strong>: </p>
<p>\[
E[X] = \sum\limits_{x} xp_X(x)
\]</p>
</li>
<li>
<p>Interpretation: average in large number of independet repetitions of the experiment</p>
</li>
<li>
<p>Elementary properties</p>
<ul>
<li>
<p>If X ≥ 0, then E(X) ≥ 0</p>
</li>
<li>
<p>If a ≤ X ≤ b, then a ≤ E[X] ≤ b</p>
</li>
<li>
<p>If c is a constant, E[c] = c</p>
</li>
<li>
<p>The expected value rule: </p>
<p>\[
E[Y] = \sum\limits_y yp_Y(y) = E[g(X)] = \sum\limits_x g(x)p_X(x)<br />
\]</p>
</li>
<li>
<p>Linearity of expectation: \(E[aX+b] = aE[X] + b\)</p>
</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#44-variance---a-measure-of-the-spread-of-a-pmf" id="44-variance---a-measure-of-the-spread-of-a-pmf">4.4 Variance - a measure of the spread of a PMF</a></h3>
<h4><a class="header" href="#441-definition-of-variance" id="441-definition-of-variance">4.4.1 Definition of variance:</a></h4>
<p>\[
var(X) = E[(X - \mu)^2] = \sum\limits_x (x - \mu)^2 p_X(x)
\]</p>
<p>standard deviation: \(\sigma_X = \sqrt{var(X)}\)</p>
<h4><a class="header" href="#442-properties-of-the-variance" id="442-properties-of-the-variance">4.4.2 Properties of the variance</a></h4>
<ul>
<li>
<p>Notation: \(\mu = E[X] \)</p>
</li>
<li>
<p>\(var(aX + b) = a^2var(X)\)</p>
</li>
<li>
<p>A useful formula:</p>
<p>\[
var(X) = E(X^2) - (E[X])^2<br />
\]</p>
</li>
</ul>
<p><strong>Summary of Expectation and Variance of Discrete Random Variables</strong></p>
<table><thead><tr><th>Random Variables</th><th align="center">Formula</th><th align="right">E(X)</th><th align="right">var(X)</th></tr></thead><tbody>
<tr><td>Bernoulli (p)</td><td align="center">\(p_X(x) = \begin{cases} 1, p(x) = p \\ 0, p(x) = 1 - p \end{cases} \)</td><td align="right">\(p\)</td><td align="right">\(p(1-p)\)</td></tr>
<tr><td>Uniform (a,b)</td><td align="center">\(p_X(x) = \frac{1}{b-a}, a ≤ x ≤ b\)</td><td align="right">\(\frac{a+b}{2}\)</td><td align="right">\(\frac{1}{12}(b-a)(b-a-2)\)</td></tr>
<tr><td>Binomial \(p \in [0,1]\)</td><td align="center">\(p_X(k) = \left(\begin{array}{c} n \\ k \end{array}  \right)p^k(1-p)^{n-k}, k = 0, 1 ..., n\)</td><td align="right">\( np \)</td><td align="right">\(np(1-p)\)</td></tr>
<tr><td>Geometric  \(0 &lt; p ≤ 1\)</td><td align="center">\(p_X(k) = (1-p)^{k-1}p, k = 1,2,3.... \)</td><td align="right">\(\frac{1}{p}\)</td><td align="right">\(\)</td></tr>
</tbody></table>
<h3><a class="header" href="#45-conditional-pmf-and-expectation-given-an-event" id="45-conditional-pmf-and-expectation-given-an-event">4.5 Conditional PMF and expectation, given an event</a></h3>
<h4><a class="header" href="#451-conditional-pmfs" id="451-conditional-pmfs">4.5.1 Conditional PMFs</a></h4>
<p>\(p_{X|A}(x|A) = P(X = x|A)\), given A = {Y = y}</p>
<p>\[
p_{X|Y}(x|y) = \frac{p_{X,Y}(x,y)}{p_Y(y)}<br />
\]</p>
<h4><a class="header" href="#452-conditional-pmfs-involing-more-than-two-random-variables" id="452-conditional-pmfs-involing-more-than-two-random-variables">4.5.2 Conditional PMFs involing more than two random variables</a></h4>
<ul>
<li>
<p>\(p_{X|Y,Z}(x|y,z) = P(X = x|Y = y, Z = z) = \frac{P(X=x,Y=y,Z=z)}{P(Y=y, Z=z)} = \frac{P_{X,Y,Z}(x,y,z)}{P_{Y,Z}(y,z)} \)</p>
</li>
<li>
<p>Multiplication rules: \(p_{X,Y,Z}(x,y,z) = p_X(x)p_{Y|X}(y|x)p_{Z|X,Y}(z|x,y) \)</p>
</li>
<li>
<p>Total probability and expectation theorems</p>
<p>\(p_X(x) = P(A_1)p_{X|A_1}(x) + ... + P(A_n)p_{X|A_n}(x) \implies p_X(x) = \sum\limits_y p_Y(y)p_{X|Y}(x|y)\)</p>
<p>\(E[X] = P(A_1)E[X|A_1] + ... + P(A_n)E[X|A_n] \implies E[X] = \sum\limits_y p_Y(y) E[X|Y = y]\)</p>
</li>
</ul>
<h3><a class="header" href="#46-multiple-random-variables-and-joint-pmfs" id="46-multiple-random-variables-and-joint-pmfs">4.6 Multiple random variables and joint PMFs</a></h3>
<h4><a class="header" href="#461-joint-pmf" id="461-joint-pmf">4.6.1 Joint PMF</a></h4>
<p>\[
p_{X,Y}(x,y) = P(X = x, Y =y)
\]</p>
<ul>
<li>
<p>\(\sum\limits_x \sum\limits_y p_{X,Y}(x,y) = 1\)</p>
</li>
<li>
<p>Marginal PMFs: \(p_X(x) = \sum\limits_y p_{X,Y}(x,y)\)</p>
<p>\(p_Y(y) = \sum\limits_x p_{X,Y}(x,y)\)</p>
</li>
</ul>
<h4><a class="header" href="#462-functions-of-multiple-random-variables" id="462-functions-of-multiple-random-variables">4.6.2 Functions of multiple random variables</a></h4>
<p>\(Z = g(X,Y)\)</p>
<ul>
<li>
<p>PMF: \(p_Z(z) = P(Z=z) =P(g(X,Y) = z) \)</p>
</li>
<li>
<p>Expected value rules: \(E[g(X,Y)] = \sum\limits_x \sum\limits_y g(x,y) p_{X,Y}(x,y)\)</p>
</li>
<li>
<p>Linearity of expectations</p>
<ul>
<li>
<p>\(E[aX + b] = aE[X] + b\)</p>
</li>
<li>
<p>\(E[X + Y] = E[X] + E[Y]\)</p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#463-independence-of-multiple-random-variables" id="463-independence-of-multiple-random-variables">4.6.3 Independence of multiple random variables</a></h4>
<ul>
<li>
<p>\(P(X = x and Y = y) = P(X = x) \times P(Y = y), for all x, y \)</p>
</li>
<li>
<p>\(P_{X|Y}(x|y) = P_X(x)\) and \(P_{Y|X}(y|x) = P_Y(y)\)</p>
</li>
<li>
<p><strong>Independence and expectations</strong></p>
<ul>
<li>
<p>In general, \(E[g(X,Y)] \neq g(E[X], E[Y])\)</p>
</li>
<li>
<p>If X, Y are independent: \(E[XY] = E[X]E[Y]\)</p>
<p>g(X) and h(Y) are also independent: \(E[g(X)h(Y)] = E[g(X)]E[h(Y)]\)</p>
</li>
</ul>
</li>
<li>
<p><strong>Independence and variances</strong></p>
<ul>
<li>
<p>Always true: \(var(aX) = a^2var(X)\) and \(var(X+a) = var(X)\)</p>
</li>
<li>
<p>In general: \(var(X+Y) \neq var(X) + var(Y)\)</p>
</li>
<li>
<p>If X, Y are independent, \(var(X,Y) = var(X) + var(Y)\)</p>
</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#5-continuous-random-variables" id="5-continuous-random-variables">5 Continuous random variables</a></h2>
<h3><a class="header" href="#51-probability-density-function-pdfs" id="51-probability-density-function-pdfs">5.1 Probability density function (PDFs)</a></h3>
<h4><a class="header" href="#511-definition" id="511-definition">5.1.1 Definition</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/120918805-91f48200-c6b6-11eb-9319-23713295480c.png" alt="image" /></p>
<p><em>PDFs are not probabilities. Their units are probability per unit length.</em></p>
<p><strong>Contiunous random variables</strong>: a random variable is continuous <strong>if it can be described by a PDF</strong>.</p>
<ul>
<li>
<p>\(P(X = a) = 0\)</p>
</li>
<li>
<p>\(f_X(x) \geq 0\)</p>
</li>
<li>
<p>\(\int_{-\infty}^{+\infty}f(x)dx = 1\)</p>
</li>
</ul>
<p><strong>Expectation/Mean</strong></p>
<p>Expection/mean of a continuous random variable: <em>average in large number of independent repetitions of the experiment</em></p>
<p>\[
E[X] = \int_{-\infty}^{+\infty}xf_X(x)dx
\]</p>
<p><strong>Properties of expectations</strong></p>
<ul>
<li>
<p>if X ≥ 0, then \(E[X] ≥ 0\)</p>
</li>
<li>
<p>if a ≤ X ≤ b, then \(a ≤ E[X] ≤ b\)</p>
</li>
<li>
<p>Expected value rule: \(E[g(X)] = \sum\limits_{x} g(x) f_X(x) dx \)</p>
</li>
<li>
<p>Linearity: \(E[aX + b] = aE(X) + b\)</p>
</li>
</ul>
<p><strong>Variance</strong></p>
<p>According to the definition of variance: \(var(X) = E[(X - \mu)^2] \)</p>
<p>\[
var(X) = \int_{-\infty}^{+\infty} (x - \mu)^2 f_X(x) dx
\] </p>
<ul>
<li>
<p>Standard deviation = \(\sigma_X = \sqrt{var(X)} \)</p>
</li>
<li>
<p>\(var(aX + b) = a^2 var(X)\)</p>
</li>
<li>
<p>\(var(X) = E[X^2] - (E[X])^2\)</p>
</li>
</ul>
<p><strong>Summary of Expectation and Variance of continuous random variables</strong></p>
<table><thead><tr><th>Random Variables</th><th align="center">Formula</th><th align="right">E(X)</th><th align="right">var(X)</th></tr></thead><tbody>
<tr><td>Uniform</td><td align="center">\(f(x) = \frac{1}{b-a}, a ≤ x ≤ b\)</td><td align="right">\(\frac{a+b}{2}\)</td><td align="right">\(\frac{(b-a)^2}{12}\)</td></tr>
<tr><td>Exponential \( \lambda &gt; 0 \)</td><td align="center">\(f(x) = \begin{cases} \lambda e^{-\lambda x}, x ≥ 0 \\ 0, x &lt; 0 \end{cases}\)</td><td align="right">\(\frac{1}{\lambda}\)</td><td align="right">\(\frac{1}{\lambda^2}\)</td></tr>
</tbody></table>
<h4><a class="header" href="#512-cumulative-distribution-functions-cdf" id="512-cumulative-distribution-functions-cdf">5.1.2 Cumulative distribution functions (CDF)</a></h4>
<p>CDF defination: \(F_X(x) = P(X ≤ x )\)</p>
<ul>
<li>
<p>Non-decreasing</p>
</li>
<li>
<p>\(F_X(x)\) tends to 1, as \(x \to \infty\)</p>
</li>
<li>
<p>\(F_X(x)\) tends to 0, as \(x \to - \infty\)</p>
</li>
</ul>
<h4><a class="header" href="#513-normalgaussian-random-variables" id="513-normalgaussian-random-variables">5.1.3 Normal(Gaussian) random variables</a></h4>
<ol>
<li>
<p>Standard normal(Gaussian) random variables</p>
<p>Stardard  normal \(N(0,1): f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \)</p>
<ul>
<li>
<p>\(E[X] = 0\)</p>
</li>
<li>
<p>\(var(X) = 1\)</p>
</li>
</ul>
</li>
<li>
<p>General normal(Gaussian) random variables</p>
<p>General  normal \(N(\mu,\sigma^2): f_X(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-(x-\mu)^2/2\sigma^2}, \sigma &gt; 0 \)</p>
<ul>
<li>
<p>\(E[X] = \mu \)</p>
</li>
<li>
<p>\( var(X) = \sigma^2 \)</p>
</li>
</ul>
<pre><code> \\( \sigma^2 \to small\\), the shape of normal distribution becomes more narrow.
</code></pre>
</li>
<li>
<p>Linear functions of a normal random variable</p>
<ul>
<li>
<p>Let \(Y = aX + b, X \sim N(\mu, \sigma^2)\)</p>
<p>\(E[Y] = a\mu + b\)</p>
<p>\(Var(Y) = a^2 \sigma^2 \)</p>
</li>
<li>
<p>Fact: \(Y \sim N(a\mu + b, a^2 \sigma^2)\)</p>
</li>
<li>
<p>Special case: a = 0. There is Y = b, \(N(b, 0)\)</p>
</li>
</ul>
</li>
</ol>
<h4><a class="header" href="#514-calculation-of-normal-probabilities" id="514-calculation-of-normal-probabilities">5.1.4 Calculation of normal probabilities</a></h4>
<ol>
<li>
<p><strong>Standard normal tables</strong> </p>
<p>\(\Phi(y) = F_Y(y) = P(Y \leq y)\) which can be find in the table, where y ≥ 0.</p>
</li>
<li>
<p>Standardizing a random variable</p>
<p>\(X \sim N(\mu, \sigma^2), \sigma^2 &gt; 0 \)</p>
<p>\(Y = \frac{X - \mu}{\sigma}\)</p>
</li>
</ol>
<h3><a class="header" href="#52-conditioning-on-an-event-multiple-continuous-rvs" id="52-conditioning-on-an-event-multiple-continuous-rvs">5.2 Conditioning on an event: multiple continuous r.v.'s</a></h3>
<p>\[
P( X \in B|A) =  \int_B f_{X|A}(x)dx
\]</p>
<h4><a class="header" href="#521-conditional-pdf-of-x-given-that-x-in-a-" id="521-conditional-pdf-of-x-given-that-x-in-a-">5.2.1 Conditional PDf of X, given that \(X \in A \)</a></h4>
<p>\[
f_{X|X \in A}(x) = \begin{cases} 0, if x \notin A \\ \frac{f_X(x)}{P(A)}, if x \in A \end{cases}
\]</p>
<h4><a class="header" href="#522-conditional-expectation-of-x-given-an-event" id="522-conditional-expectation-of-x-given-an-event">5.2.2 Conditional expectation of X, given an event</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/121066009-b5f4b800-c7c9-11eb-9e82-cca4ded3a17f.png" alt="image" /></p>
<h4><a class="header" href="#523-memorylessness-of-the-exponential-pdf" id="523-memorylessness-of-the-exponential-pdf">5.2.3 Memorylessness of the exponential PDF</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/121071392-2a325a00-c7d0-11eb-8e77-c14ded14fe0c.png" alt="image" /></p>
<h4><a class="header" href="#524-total-probability-and-expectation-theorems" id="524-total-probability-and-expectation-theorems">5.2.4 Total probability and expectation theorems</a></h4>
<ul>
<li>Probability theorem: </li>
</ul>
<p>\[
P(B) = P(A_1)P(B|A_1) + \dotsb + P(A_n)P(B|A_n)
\]</p>
<ul>
<li>For the discrete random variable: </li>
</ul>
<p>\[
p_X(x) = P(A_1)p_{X|A_1}(x) + \dotsb + P(A_n)p_{X|A_n}(x)
\]</p>
<ul>
<li>For CDF: </li>
</ul>
<p>\[
F_X(x) = P(X \leq x) = P(A_1)P(X \leq x | A_1) + \dotsb + P(A_n)P(X \leq x | A_n) 
\\= P(A_1)F_{X|A_1}(x) + \dotsb + P(A_n)F_{X|A_n}(x)
\]</p>
<ul>
<li>For PDF, the derivative of CDF:</li>
</ul>
<p>\[
f_X(x) = P(X \leq x) = P(A_1)f_{X|A_1}(x) + \dotsb + P(A_n)f_{X|A_n}(x)
\]</p>
<ul>
<li>Integral above equation, we will obtain the expectation equation:</li>
</ul>
<p>\[
\int xf_X(x)dx = P(A_1) \int xf_{X|A_1}(x)dx + \dotsb + P(A_n) \int xf_{X|A_n}(x)dx
\]</p>
<p>\[
E[X] = P(A_1)E[X|A_1] + \dotsb + P(A_n)E[X|A_n]<br />
\]</p>
<h3><a class="header" href="#53-mixed-random-varibles" id="53-mixed-random-varibles">5.3 Mixed random varibles</a></h3>
<h4><a class="header" href="#531-mixed-distirbutions" id="531-mixed-distirbutions">5.3.1 Mixed distirbutions</a></h4>
<p>\[
X = \begin{cases} Y, \text{with probability } p \text{ (Y discrete)}\\ Z, \text{with probability } 1-p \text{ (Z continuous)} \end{cases}<br />
\]</p>
<ul>
<li>
<p>do not have PDF or PMF but can be defined with CDF and expectation</p>
<p>\[
F_X(x) = p P(Y \leq x) + (1-p) P(Z \leq x)
\\
=pF_Y(x) + (1-p)F_Z(x)
\\
= E[X] = p E[Y] + (1-p) E[Z]
\]</p>
<p><img src="https://user-images.githubusercontent.com/41487483/121077061-6fa65580-c7d7-11eb-84f5-a7c1d5c36df3.png" alt="image" /></p>
</li>
</ul>
<h4><a class="header" href="#532-joint-pdfs" id="532-joint-pdfs">5.3.2 Joint PDFs</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/121728365-75f54400-caed-11eb-9935-66e24af94023.png" alt="image" /></p>
<ul>
<li>
<p>Joint PDFs are denoted as \(f_{X,Y}(x,y)\): probaility per unit area</p>
<p>When X = Y, equal to a line, meaning X and Y are not joint PDFs.</p>
</li>
</ul>
<h4><a class="header" href="#533-from-the-joint-to-the-marginal" id="533-from-the-joint-to-the-marginal">5.3.3 From the joint to the marginal</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/121731040-b73b2300-caf0-11eb-8a17-90bb4190224e.png" alt="image" /></p>
<h4><a class="header" href="#534-joint-cdf" id="534-joint-cdf">5.3.4 Joint CDF</a></h4>
<p>\[
F_{X,Y}(x,y) = P(X \leq x, Y \leq y) = \int\limits_{-\infty}^{y} \int\limits_{-\infty}^{x} f_{x,y}(s,t)dsdt 
\]</p>
<h3><a class="header" href="#54-conditioning-on-a-random-variable-and-bayers-rule" id="54-conditioning-on-a-random-variable-and-bayers-rule">5.4 Conditioning on a random variable and Bayers rule</a></h3>
<h4><a class="header" href="#541-conditional-pdfs-given-another-rv" id="541-conditional-pdfs-given-another-rv">5.4.1 Conditional PDFs, given another r.v.</a></h4>
<ul>
<li>
<p>\(f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}\), if \(f_y(y) &gt; 0\)</p>
<ul>
<li>
<p>\(f_{X|Y}(x|y) \geq 0\)</p>
</li>
<li>
<p>Think of value of Y as fixed at some y shape of \(f_{X|Y}(\cdot|y)\): slice of the joint</p>
</li>
<li>
<p>multiplication rule: </p>
<p>\[
f_{X|Y}(x,y) = f_Y(y) \cdot f_{X|Y}(x|y)<br />
\]</p>
</li>
</ul>
</li>
<li>
<p>\(P(X \in A | Y = y) = \int_A f_{X|Y}(x/y)dx\)</p>
</li>
</ul>
<h4><a class="header" href="#542-total-probability-and-expectation-theorems" id="542-total-probability-and-expectation-theorems">5.4.2 Total probability and expectation theorems</a></h4>
<ul>
<li>
<p>Anolog to the PMFs of discrete randome varable \(p_X(x) = \sum\limits_y p_Y(y)p_{X|Y}(x|y)\)</p>
<p>For continuous r.v., there is </p>
<p>\[
f_X(x) = \sum_{-\infty}^{\infty} f_Y(y)f_{X|Y}(x|y)dy<br />
\]</p>
</li>
<li>
<p>Anolog to the Expectation of discrete randome varable \(E[X|Y=y] = \sum\limits_x x p_{X|Y}(x|y)\)</p>
<p>For continuous r.v., there is </p>
<p>\[
E[X|Y=y] = \int_{-\infty}^{\infty} xf_{X|Y}(x|y)dx<br />
\]</p>
</li>
<li>
<p>Anolog to the discrete randome varable \(E[X] = \sum\limits_y p_Y(y) E[X|Y=y]\)</p>
<p>For continuous r.v., there is </p>
<p>\[<br />
E[X] = \int_{-\infty}^{\infty} f_Y(y)E[X|Y=y]dy<br />
\\ = \int_{-\infty}^{\infty} xf_X(x)dx<br />
\]</p>
</li>
<li>
<p>Expected value rule</p>
<p>\[
E[g(X)|Y=y] = \int_{-\infty}^{\infty} g(x)f_{X|Y}(x|y)dx<br />
\]</p>
</li>
</ul>
<h4><a class="header" href="#543-independence" id="543-independence">5.4.3 Independence</a></h4>
<p>\[
f_{X,Y}(x,y) = f_X(x)f_Y(y), for all x and y<br />
\]</p>
<ul>
<li>
<p>\(f_{X,Y}(x,y) = f_X(x)\), for all y with \(f_Y(y) &gt; 0\) and all x</p>
</li>
<li>
<p>If X, Y are <strong>independent</strong>:</p>
<p>\[
E[XY] = E[X]E[Y] \\
var(X + Y) = var(X) + var(Y)
\]</p>
<p>g(X) and h(Y) are also independent: \(E[g(X)h(Y)] = E[g(X)] \cdot E[h(Y)]\)</p>
</li>
</ul>
<h4><a class="header" href="#544-the-bayes-rule-----a-theme-with-variations" id="544-the-bayes-rule-----a-theme-with-variations">5.4.4 The Bayes rule --- a theme with variations</a></h4>
<ul>
<li>
<p>For discrete r.v., </p>
<ul>
<li>
<p>\(p_{X|Y}(x|y) = \frac{p_X(x) p_{Y|X}(y|x)}{p_Y(y)}\)</p>
</li>
<li>
<p>\(p_Y(y) = \sum\limits_{x'} p_X(x')p_{Y|X}(y|x')\)</p>
</li>
</ul>
</li>
<li>
<p>For continuous r.v., </p>
<ul>
<li>
<p>\(f_{X|Y}(x|y) = \frac{f_X(x) f_{Y|X}(y|x)}{_Y(y)}\)</p>
</li>
<li>
<p>\(p_Y(y) = \int\limits f_X(x')f_{Y|X}(y|x')\)</p>
</li>
</ul>
</li>
<li>
<p>One discrete and one continuous r.v.</p>
<p><img src="https://user-images.githubusercontent.com/41487483/121778872-456ae400-cb99-11eb-8fc6-d1cb9ea4f3f2.png" alt="image" /></p>
</li>
</ul>
<h2><a class="header" href="#unit-6-further-topics-on-random-variables" id="unit-6-further-topics-on-random-variables">Unit 6 Further topics on random variables</a></h2>
<h3><a class="header" href="#61-derived-distributions" id="61-derived-distributions">6.1 Derived distributions</a></h3>
<h4><a class="header" href="#611-a-linear-function-y---ax--b" id="611-a-linear-function-y---ax--b">6.1.1 A linear function \(Y =  aX + b\)</a></h4>
<ul>
<li>
<p>Discrete r.v. </p>
<p>\(
p_Y(y) = p_X(\frac{y-b}{a})
\)</p>
</li>
<li>
<p>Continuous r.v.</p>
<p>\(
f_Y(y) = \frac{1}{|a|}f_X(\frac{y-b}{a})
\)</p>
<ul>
<li>
<p>A linear function of normal r.v. is normal</p>
<p>If \(X \sim N(\mu, \sigma^2)\), then \(aX + b \sim N(a\mu + b, a^2\sigma^2)\)</p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#612-a-general-function-gx-of-a-continuous-rv" id="612-a-general-function-gx-of-a-continuous-rv">6.1.2 A general function \(g(X)\) of a continuous r.v.</a></h4>
<p><strong>Two-step procedure:</strong></p>
<ul>
<li>
<p>Find the CDF of Y: \(F_Y(y) = P(Y \leq y) = P(g(x) \leq y)\) and the valid range of y</p>
</li>
<li>
<p>Differentiate: \(f_Y(y) = \frac{dF_Y(y)}{dy}\)</p>
</li>
</ul>
<ol>
<li>
<p>A general formula for the PDF of \(Y = g(X)\) when <em>g</em> is monotomic</p>
<p>\[
f_Y(y) = f_X(h(y))\left|\frac{dh(y)}{dy}\right|<br />
\]</p>
<p>\(x = h(y)\) is the inverse function of \(y = g(x)\)</p>
</li>
<li>
<p>A nonmonotonic example \(Y = X^2\)</p>
<ul>
<li>
<p>the discrete case: \(p_Y(y) = p_X(\sqrt{y}) + p_X(-\sqrt{y})\)</p>
</li>
<li>
<p>the continuous case: \(f_Y(y) = f_X(\sqrt{y})\frac{1}{2\sqrt{y}} + p_X(-\sqrt{y})\frac{1}{2\sqrt{y}}\)</p>
</li>
</ul>
</li>
<li>
<p>A function of multiple r.v.'s: \(Z = g(X,Y)\)</p>
<p><img src="https://user-images.githubusercontent.com/41487483/122451427-69b72e00-cfa8-11eb-9aa5-b1c0855886d0.png" alt="image" /></p>
</li>
</ol>
<h3><a class="header" href="#62-sums-of-independent-vadom-variables" id="62-sums-of-independent-vadom-variables">6.2 Sums of independent vadom variables</a></h3>
<h4><a class="header" href="#621-the-distribution-of-x--y-the-discrete-case" id="621-the-distribution-of-x--y-the-discrete-case">6.2.1 The distribution of \(X + Y\): the discrete case</a></h4>
<p>Z = X + Y; X,Y independent, discrete known PMFs</p>
<p>\[
p_Z(z) = \sum\limits_x p_X(x)p_Y(z-x)<br />
\]</p>
<p><strong>Dsicrete convoltion mechanics</strong></p>
<ol>
<li>
<p>Flip the PMF of Y and put it underneath the PMF of X</p>
</li>
<li>
<p>Shift the flipped PMF by z </p>
</li>
<li>
<p>Cross-multiply and add</p>
</li>
</ol>
<h4><a class="header" href="#622-the-distribution-of-x--y-the-continous-case" id="622-the-distribution-of-x--y-the-continous-case">6.2.2 The distribution of \(X + Y\): the continous case</a></h4>
<p>Z = X + Y; X,Y independent, continuous known PDFs</p>
<p>\[
f_Z(z) = \int\limits_x f_X(x)f_Y(z-x)dx<br />
\]</p>
<ul>
<li>
<p>conditional on \(X = x\): </p>
<p>\[
f_{Z|x}(z|x) = f_Y(z-x)<br />
\]</p>
<p>which can then be used to calculate Joint PDF of Z and X and marginal PDF of Z.</p>
</li>
<li>
<p>Same mechanics as in discrete case</p>
</li>
</ul>
<h4><a class="header" href="#623-the-sum-of-independent-normal-rvs" id="623-the-sum-of-independent-normal-rvs">6.2.3 The sum of independent normal r.v.'s</a></h4>
<ul>
<li>
<p>\(X \sim N(\mu_x, \sigma_x^2), Y \sim N(\mu_y, \sigma_y^2\) <strong>Independent</strong></p>
<p>\(Z = X + Y: \sim N(N(\mu_x + \mu_y,  \sigma_x^2 + \sigma_y^2))\)</p>
<p><strong>The sum of finitely many independent normals is normal</strong></p>
</li>
</ul>
<h3><a class="header" href="#63-covariance-协方差" id="63-covariance-协方差">6.3 Covariance (协方差)</a></h3>
<h4><a class="header" href="#631-definition" id="631-definition">6.3.1 Definition</a></h4>
<p>\[
cov(X,Y) = E[(X - E[X]) \cdot (Y - E(Y))]<br />
\]</p>
<ul>
<li>If \(X,Y\) <strong>independent: \(cov(X,Y) = 0 \)</strong> </li>
</ul>
<p><em>convers is not true!</em></p>
<h4><a class="header" href="#632-covariance-properties" id="632-covariance-properties">6.3.2 Covariance properties</a></h4>
<ol>
<li>
<p>\(cov(X,X) = var(X) = E[X^2] - (E[X])^2\)</p>
</li>
<li>
<p>\(cov(aX+b,Y) = a \cdot cov(X,Y)\)</p>
</li>
<li>
<p>\(cov(X,Y+Z) = cov(X,Y) + cov(X,Z)\)</p>
</li>
</ol>
<p><strong>Practical covariance formula:</strong> </p>
<p>\[
cov(X,Y) = E[XY] - E[X]E[Y]
\]</p>
<h4><a class="header" href="#633-the-variance-of-a-sum-of-random-variables" id="633-the-variance-of-a-sum-of-random-variables">6.3.3 The variance of a sum of random variables</a></h4>
<ul>
<li>
<p>two r.v.s</p>
<p>\[
var(X_1 + X_2) = var(X_1) + var(X_2) + 2cov(X_1,X_2)<br />
\]</p>
<p><em>X,Y indepedent, then \(var(X_1 + X_2) = var(X_1) + var(X_2)\)</em></p>
</li>
<li>
<p>multiple r.v.s</p>
<p>\[
var(X_1 + \dots + X_n) = \sum\limits_{i=1}^nvar(X_i) + \sum\limits_{(i,j):i \neq j}^n cov(X_i,X_j)<br />
\]</p>
<p><em>\(\sum\limits_{(i,j):i \neq j}^n \) contains \((n^2 - n)\) terms</em></p>
</li>
</ul>
<h3><a class="header" href="#64-the-correlation-coefficient" id="64-the-correlation-coefficient">6.4 The correlation coefficient</a></h3>
<p>\[
\rho(X,Y) = E\left[\frac{(X - E[X])}{\sigma_X} \cdot \frac{(Y - E[Y])}{\sigma_Y}\right] = \frac{cov(X,Y)}{\sigma_X \sigma_Y}
\]</p>
<h4><a class="header" href="#641-interpretation-of-correlation-coeffecient" id="641-interpretation-of-correlation-coeffecient">6.4.1 Interpretation of correlation coeffecient</a></h4>
<ul>
<li>
<p>Dimensionless version of covariance </p>
</li>
<li>
<p>Measure of the defree of &quot;association&quot; between X and Y</p>
</li>
<li>
<p>Association does not imply causation or influence</p>
</li>
<li>
<p>Correlation often refleces underlying, common, hidden factor</p>
</li>
</ul>
<h4><a class="header" href="#642-key-properties-of-the-correlation-coeffecient" id="642-key-properties-of-the-correlation-coeffecient">6.4.2 Key properties of the correlation coeffecient</a></h4>
<ul>
<li>
<p>\(-1 \leq \rho \leq 1\)</p>
</li>
<li>
<p><strong>Independent</strong> \(\implies \rho = 0\) &quot;uncorrelated&quot; (converse is not true)</p>
</li>
<li>
<p>\(|\rho| = 1 \Leftrightarrow\) linearly related</p>
</li>
<li>
<p>\(cov(aX+b, Y) = a \cdot cov(X,Y) \implies \rho(aX+b,Y) = sigma(a)\rho(X,Y)\)</p>
</li>
</ul>
<h3><a class="header" href="#65-conditional-expectation-and-variance-as-a-random-variable" id="65-conditional-expectation-and-variance-as-a-random-variable">6.5 Conditional expectation and variance as a random variable</a></h3>
<h4><a class="header" href="#651-conditional-expecation" id="651-conditional-expecation">6.5.1 Conditional expecation</a></h4>
<ul>
<li><strong>Definition</strong>: \(g(Y)\) is the <em>random variable</em> that takes the value \(E[X|Y=y]\), if \(Y\) happens to take the value \(y\).</li>
</ul>
<p>\[
E[X|Y] = g(Y)<br />
\]</p>
<ul>
<li><strong>Law of iterated expectations</strong></li>
</ul>
<p>\[
E[E[X|Y]] = E[g(Y)] = E[X]<br />
\]</p>
<h4><a class="header" href="#652-conditional-variance" id="652-conditional-variance">6.5.2 Conditional variance</a></h4>
<ul>
<li>
<p>Variance fundamentals</p>
<p>\[
var(X) = E[(X - E[X])^2] \\
var(X|Y=y) = E[(X - E[X|Y=y])^2|Y=y]
\]</p>
</li>
</ul>
<p><strong>var(X|Y) is the r.v. that takes the value var(X|Y=y), when Y=y</strong></p>
<ul>
<li>
<p><strong>Law of total variance</strong></p>
<p>\[
var(X) = E[var(X|Y)] + var(E[X|Y])<br />
\]</p>
<p><em>var(X) = (average variability within sections) + (variability between sections)</em></p>
</li>
</ul>
<h3><a class="header" href="#66-sum-a-random-number-of-indepedent-rvs" id="66-sum-a-random-number-of-indepedent-rvs">6.6 Sum a random number of indepedent r.v.'s</a></h3>
<p><em>Example of shopping</em></p>
<ul>
<li>
<p>N: number of stores visited (N is a nonnegative integer r.v.)</p>
</li>
<li>
<p>\(X_i\): money spent in store i </p>
<ul>
<li>
<p>\(X_i\) independent, identically distributed</p>
</li>
<li>
<p>independent of N</p>
</li>
</ul>
</li>
<li>
<p>Let \(Y = X_1 + \dots + X_N\)</p>
</li>
</ul>
<h4><a class="header" href="#661-expecatation-of-the-sum" id="661-expecatation-of-the-sum">6.6.1 Expecatation of the sum</a></h4>
<p>Based on the Law of iterated expectations:</p>
<p>\[
E[Y] = E[E[Y|N]] = E[N \cdot E[X]] = \cdot E[X]E[N]<br />
\]</p>
<h4><a class="header" href="#662-variance-of-the-sum" id="662-variance-of-the-sum">6.6.2 Variance of the sum</a></h4>
<p>Based on the Law of total variance: \(var(Y) = E[var(Y|N)] + var(E[Y|N])\):</p>
<p>\[
var(Y) = E[N]var(X) + (E[X])^2var(N) 
\]</p>
<h2><a class="header" href="#unit-7-bayesian-inferences" id="unit-7-bayesian-inferences">Unit 7 Bayesian inferences</a></h2>
<h3><a class="header" href="#71-introduction-to-bayesian-inference" id="71-introduction-to-bayesian-inference">7.1 Introduction to Bayesian inference</a></h3>
<h3><a class="header" href="#72-linear-models-with-normal-noise" id="72-linear-models-with-normal-noise">7.2 Linear models with normal noise</a></h3>
<h3><a class="header" href="#73-least-mean-squares-lms-estimation" id="73-least-mean-squares-lms-estimation">7.3 Least mean squares (LMS) estimation</a></h3>
<h3><a class="header" href="#74-linear-least-mean-squares-llms-estimation" id="74-linear-least-mean-squares-llms-estimation">7.4 Linear least mean squares (LLMS) estimation</a></h3>
<h4><a class="header" href="#741-llms-formulation" id="741-llms-formulation">7.4.1 LLMS formulation</a></h4>
<p>\(\hat{\Theta} = aX + b\), minimize \(E[(\hat{\Theta} - \Theta)^2]\)</p>
<h4><a class="header" href="#742-llms-solution" id="742-llms-solution">7.4.2 LLMS solution</a></h4>
<p>Minimize \(E[(\hat{\Theta} - \Theta)^2]\), that is \(E[(\Theta - aX - b)^2]\)</p>
<p>\[
\hat{\Theta_L} = E[\Theta] + \frac{Cov(\Theta,X)}{var(X)}(X - E[X]) = E[\Theta] + \rho \frac{\sigma_\Theta}{\sigma_X}(X - E[X])<br />
\]</p>
<p>\(\rho\) corelation coefficiency</p>
<ul>
<li>Only means, variances, covariances matter (we do not need to know everything)</li>
</ul>
<p>\[
E[(\hat{\Theta_L} - \Theta)^2] = (1 - \rho^2)var(\Theta)
\]</p>
<ul>
<li>LLMS with multiple observations</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../statistics/statistics.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../statistics/statinfer.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../statistics/statistics.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../statistics/statinfer.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
