<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Inferential Statistics - Note</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../favicon.svg">
        
        
        <link rel="shortcut icon" href="../favicon.png">
        
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        
        <link rel="stylesheet" href="../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../chapter_1.html"><strong aria-hidden="true">1.</strong> Chapter 1</a></li><li class="chapter-item expanded "><a href="../git.html"><strong aria-hidden="true">2.</strong> Git</a></li><li class="chapter-item expanded "><a href="../tips.html"><strong aria-hidden="true">3.</strong> Visit with the Client &amp; Setup Overview</a></li><li class="chapter-item expanded "><a href="../frontend/frontend.html"><strong aria-hidden="true">4.</strong> Frontend</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../frontend/vue3.html"><strong aria-hidden="true">4.1.</strong> Vue3 note</a></li><li class="chapter-item expanded "><a href="../frontend/css.html"><strong aria-hidden="true">4.2.</strong> CSS</a></li></ol></li><li class="chapter-item expanded "><a href="../sql/sql.html"><strong aria-hidden="true">5.</strong> SQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../sql/duke.html"><strong aria-hidden="true">5.1.</strong> Duke-coursera</a></li></ol></li><li class="chapter-item expanded "><a href="../python/python.html"><strong aria-hidden="true">6.</strong> Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../python/Coursera-Michigan.html"><strong aria-hidden="true">6.1.</strong> Python-coursera-Michigan</a></li><li class="chapter-item expanded "><a href="../python/leanningfrommis.html"><strong aria-hidden="true">6.2.</strong> Learning in a hard way</a></li></ol></li><li class="chapter-item expanded "><a href="../statistics/statistics.html"><strong aria-hidden="true">7.</strong> Statistics rewind</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../statistics/MITx6.431x.html"><strong aria-hidden="true">7.1.</strong> Probability - The Science of Uncertainty and Data</a></li><li class="chapter-item expanded "><a href="../statistics/statinfer.html"><strong aria-hidden="true">7.2.</strong> Improve your statistical inferences</a></li><li class="chapter-item expanded "><a href="../statistics/inferentialstat.html" class="active"><strong aria-hidden="true">7.3.</strong> Inferential Statistics</a></li><li class="chapter-item expanded "><a href="../statistics/python.html"><strong aria-hidden="true">7.4.</strong> Statistics with Python</a></li><li class="chapter-item expanded "><a href="../statistics/problems.html"><strong aria-hidden="true">7.5.</strong> Common problems</a></li></ol></li><li class="chapter-item expanded "><a href="../dataviztools/dataviztools.html"><strong aria-hidden="true">8.</strong> Data Viz</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../dataviztools/projects.html"><strong aria-hidden="true">8.1.</strong> Dataviz Projects</a></li></ol></li><li class="chapter-item expanded "><a href="../english/english.html"><strong aria-hidden="true">9.</strong> English</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../english/speaking.html"><strong aria-hidden="true">9.1.</strong> Speaking English</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Note</h1>

                    <div class="right-buttons">
                        
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#inferential-statistics" id="inferential-statistics">Inferential Statistics</a></h1>
<p><a href="https://www.coursera.org/learn/inferential-statistics-intro/home/welcome">Here is the course link!</a></p>
<p><a href="https://www.notion.so/Inferential-Statistics-5dd1ac55e304409898a5877aadff7ecc">Summary of leaning objectives for each section</a></p>
<h2><a class="header" href="#1-clt-and-sampling" id="1-clt-and-sampling">1 CLT and Sampling</a></h2>
<h3><a class="header" href="#11-sampling-variability-and-clt" id="11-sampling-variability-and-clt">1.1 Sampling Variability and CLT</a></h3>
<h4><a class="header" href="#111-sample-distribution-and-sampling-distribution" id="111-sample-distribution-and-sampling-distribution">1.1.1 Sample distribution and sampling distribution</a></h4>
<ul>
<li>
<p>Sample distribution: sample mean and sample variability (standard deviation)</p>
</li>
<li>
<p>Sampling distribution</p>
<p>population mean (\(\mu \)) and population standard deviation (\(\sigma\))</p>
<p>\[
\mu = \frac{x_1 + x_2 + ... + x_N}{N}
\]</p>
<p>\[
\sigma = \sqrt{\frac{\sum\limits_{i=1}^{N}(x_i - \bar{x})^2}{N}}
\]</p>
<p><em>Most of time, population standard deviation \(\sigma\) is not known. Thus, \(\sigma\) is usually replaced by sampling standard deviation s</em></p>
<ul>
<li>
<p><strong>mean</strong>(\(\bar{x}) \approx \mu \) </p>
</li>
<li>
<p><strong>standard error:</strong>  \(SE = \frac{\sigma}{\sqrt{n}}\) &lt; \(\sigma\)</p>
</li>
</ul>
</li>
</ul>
<p><a href="https://gallery.shinyapps.io/CLT_mean/">The link to check up the shape of population distribution</a></p>
<h4><a class="header" href="#112-central-limit-theorem-clt" id="112-central-limit-theorem-clt">1.1.2 Central Limit Theorem (CLT)</a></h4>
<p><strong>The distribution of sample statistics is nearly normal, centered at the population mean, and with a standard error equal to the population standard deviation divided by square root of the sample size.</strong></p>
<p>\[
\bar{x} \sim N(mean = \mu, SE = \frac{\sigma}{\sqrt{n}}) 
\]</p>
<p><em>\(N\) refers to the shape of distribution, meaning normal distribution.</em></p>
<p><em>\(\sigma\) is usually unknown, so s is used to replace \(s\) - sampling standard deviation</em></p>
<h4><a class="header" href="#113-other-important-concepts-and-rules" id="113-other-important-concepts-and-rules">1.1.3 Other important concepts and rules</a></h4>
<ul>
<li>
<p><strong>standard deviation (\(\sigma\)) vs. standard error (SE)</strong></p>
<ul>
<li>
<p>\(\sigma\) measures the variability in the data</p>
</li>
<li>
<p>SE measures the variability in the sample mean (point estimates)</p>
</li>
</ul>
</li>
<li>
<p>sample size increases -&gt; SE decreases <em>(either from conceptual or mathematically \(SE = \frac{\sigma}{\sqrt{n}}\) point of view)</em></p>
</li>
<li>
<p>To reduce skewness, either increase sample size (observations) or number of samples</p>
</li>
<li>
<p><strong>Sampling distribution will be nearly normal only if (the condition of CLT)</strong></p>
<ul>
<li>
<p>the sample size is sufficiently large (n ≥ 30 or even larger if the data are considerably skewed) or the population is known to have a normal distribution</p>
</li>
<li>
<p>the observations in the sample are independent: random sample/assignment and n &lt; 10% of population if sampling without replacement</p>
</li>
</ul>
</li>
</ul>
</br>
<h3><a class="header" href="#12-confidential-intervals" id="12-confidential-intervals">1.2 Confidential Intervals</a></h3>
<h4><a class="header" href="#121-confidential-intervals" id="121-confidential-intervals">1.2.1 Confidential Intervals</a></h4>
<p><strong>confidence interval</strong> is defined as the plausible range of values for a population parameter. </p>
<p><strong>confidence level</strong> is defined as the percentage of random samples which  yield confidence intervals that capture the true population parameter.</p>
<p><strong>confidence interval for a population mean:</strong></p>
<p>\[
\bar{x} \pm z\frac{s}{\sqrt{n}}<br />
\] </p>
<p><strong>margin of error</strong> (ME) = \(z\frac{s}{\sqrt{n}} \)</p>
<ul>
<li>for 95% CI: \(\bar{x} \pm 2SE\) i.e., \(ME = 2SE\)</li>
</ul>
<p><em>conditions for this confidence interval is the same as conditions for CLT (independent and sample size)</em></p>
<p><img src="https://user-images.githubusercontent.com/41487483/119108985-0fff2a80-ba21-11eb-85e6-edf4997e6839.png" alt="image" /></p>
<p><a href="http://www.z-table.com/">z-table</a></p>
<h4><a class="header" href="#122-z-score-not-covered-in-the-course" id="122-z-score-not-covered-in-the-course">1.2.2 z-score (not covered in the course)</a></h4>
<ul>
<li>
<p><a href="https://www.usablestats.com/lessons/zarea">z-score for a single value</a> </p>
<p>Given we know the population parameters (\(\mu\) and \(\sigma\)), calculate z-score for any individual in the population:</p>
<p>\[
z = \frac{(x - \mu)}{\sigma}<br />
\]</p>
<p>Using z-table, the probability can be calculated.</p>
</li>
<li>
<p><a href="https://www.usablestats.com/lessons/1samplez">z-score for a sample mean</a></p>
<p>\[
z = \frac{(\bar{x} - \mu)}{\frac{\sigma}{\sqrt{n}}}<br />
\]</p>
</li>
<li>
<p><strong>Empirical rule</strong></p>
<ul>
<li>
<p>68% of values fall within 1 SE of the mean</p>
</li>
<li>
<p>95% fall within 2 SE of the mean</p>
</li>
<li>
<p>99% fall within 3 SE of the mean</p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#123-accuracy-vs-precision" id="123-accuracy-vs-precision">1.2.3 Accuracy vs. Precision</a></h4>
<ul>
<li>
<p><strong>Accuracy</strong>: whether or not the CI contains the true population paramter.</p>
</li>
<li>
<p><strong>Precision</strong>: the width of a confidence intervals.</p>
</li>
</ul>
<p>Increasing CL, accuracy increases but precision decreases.</p>
<ul>
<li>To get a higher precision and high accuracy - increase sample size</li>
</ul>
<h3><a class="header" href="#123-required-sample-size-for-me" id="123-required-sample-size-for-me">1.2.3 Required sample size for ME</a></h3>
<p>\[
ME = z \frac{s}{\sqrt{n}}    \rightarrow n = \Bigg(\frac{z s}{ME}\Bigg)^2
\]</p>
<h2><a class="header" href="#13-r-vs-sampling-distribution" id="13-r-vs-sampling-distribution">1.3 R vs. sampling distribution</a></h2>
<ol>
<li>Load the package and dataset(ames)</li>
</ol>
<pre><code class="language-r">    library(statsr)
    library(dplyr)
    library(shiny)
    library(ggplot2)

    data(ames)
</code></pre>
<ol start="2">
<li>Distribution of areas of homes and summary statistics</li>
</ol>
<pre><code class="language-r">ames %&gt;%
    summarise(mu = mean(area), pop_med = median(area), 
        sigma = sd(area), pop_iqr = IQR(area),
        pop_min = min(area), pop_max = max(area),
        pop_q1 = quantile(area, 0.25),  # first quartile, 25th percentile
        pop_q3 = quantile(area, 0.75))  # third quartile, 75th percenti
</code></pre>
<ol start="3">
<li>Sample randome 50 houses and calculate the average area</li>
</ol>
<pre><code class="language-r">samp1 &lt;- ames %&gt;%
    sample_n(size=50)

samp1 %&gt;%
    summarise(x_bar = mean(area))

# or combine above two code chunks into one
samp1 &lt;- ames %&gt;%
    sample_n(size=50) %&gt;%
        summarise(x_bar = mean(area))
</code></pre>
<ol start="4">
<li>Estimate population mean by using sampling distribution</li>
</ol>
<p>Take 15,000 samples of size 50 from the population (<code>rep_sample_n</code>), calculate the mean of each sample, and store each result in a vector called 'sample_means50'.</p>
<pre><code class="language-r">sample_means50 &lt;- ames %&gt;%
  rep_sample_n(size = 50, reps = 15000, replace = TRUE) %&gt;%
    summarise(x_bar = mean(area))

ggplot(data = sample_means50, aes(x = x_bar)) +
  geom_histogram(binwidth = 20)
</code></pre>
<p>To get the summary statistics of 15,000 sample means, analyze the statistics from the 'sample_means50', which is actually a dataset containing 15,000 observations(x_bar).</p>
<pre><code class="language-r">sample_means50 %&gt;%
    summarise(sampling_x_bar = mean(x_bar))
</code></pre>
<h2><a class="header" href="#14-python-vs-sampling-distribution" id="14-python-vs-sampling-distribution">1.4 Python vs. sampling distribution</a></h2>
<ol>
<li>Load packages and import dataset</li>
</ol>
<pre><code class="language-py">import pandas as pd
import numpy as np
import random as random
import math
import matplotlib.pyplot as plt

ames = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/ames.csv&quot;)
#ames.head
#ames.columns
</code></pre>
<ol start="2">
<li>Distribution of population</li>
</ol>
<pre><code class="language-py">mu = np.average(ames[&quot;Lot.Area&quot;])
sigma = np.std(ames[&quot;Lot.Area&quot;])

plt.hist(ames[&quot;Lot.Area&quot;],30, range=[0, mu+5*sigma])
plt.show()
#right skewed distribution
</code></pre>
<ol start="3">
<li>Randomly take 10 samples</li>
</ol>
<pre><code class="language-py">samp1 = ames.sample(n=10,replace=True)
</code></pre>
<ol start="4">
<li>Take 1000 samples with size 200</li>
</ol>
<pre><code class="language-py">size = 200
num_samp = 1000
samp_mean = []

for m in range(num_samp):
  samp = ames.sample(n=size,replace=True)
  x_bar_samp = np.average(samp[&quot;Lot.Area&quot;])
  samp_mean.append(x_bar_samp)
  m += 1

x_bar_samp_mean = np.average(samp_mean)
x_bar_samp_se = np.std(samp_mean)/(math.sqrt(size))

print(x_bar_samp_mean)
print(x_bar_samp_se)

plt.hist(samp_mean, 20, range=[5000,15000])
plt.show()
</code></pre>
</br>
<h2><a class="header" href="#2-hypothesis-testing-and-significance" id="2-hypothesis-testing-and-significance">2 Hypothesis testing and significance</a></h2>
<h3><a class="header" href="#21-hypothesis-testing-for-a-mean" id="21-hypothesis-testing-for-a-mean">2.1 Hypothesis testing (for a mean)</a></h3>
<ul>
<li>
<p>Null hypothesis - \(H_0\) </p>
</li>
<li>
<p>Alternative hypothesis - \(H_A\)</p>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/119312937-3e744400-bc73-11eb-9396-704d391112eb.png" alt="image" /></p>
<p><em>The hypothesis is always about pop.parameters, never about sample statistics (because the sample statistics is certain).</em></p>
<ul>
<li>
<p><strong>p-value</strong> - P(observed or more extreme outcome | \(H_0\) true)</p>
<p>Given \(n = 50, \bar{x} = 3.2, s = 1.74, SE = 0.246\) </p>
<p>We are looking for \(P(\bar{x} &gt; 3.2 | H_0 : \mu = 3) \)</p>
<p>Since we believe that null hypothesis is true, \(\bar{x} \sim N(\mu = 3, SE = 0.246)\) based on the CLT.</p>
<p><em>test statistics</em>: z-score = (3.2-3)/0.246 = 0.81, which is used to calculate the p-value (the probability of observing data at least favorable to the alternative hypothesis as our current data set, if the null hypothesis was true)</p>
<p>p-value = P(z &gt; 0.81) = 0.209</p>
</li>
</ul>
<p><strong>Decision based on the p-value</strong></p>
<ul>
<li>
<p>p-value &lt; the <strong>significant level</strong>, \(\alpha\) (usually 5%): it is unlikely to observe the data if the null hypothesis is true: <a style="color:red">Reject \(H_0\)</a></p>
</li>
<li>
<p>p-value ≥ \(\alpha\): it is likely to occur even if the null hypothesis were true: <a style="color:red"> Do no reject \(H_0\)</a></p>
</li>
</ul>
<p><strong>two-sided(tailed) tests</strong></p>
<p>In the same case, \(P(\bar{x} &gt; 3.2 \text{  or  } \bar{x} &gt; 2.8| H_0 : \mu = 3) \)</p>
<p>p-value = \(P(z &gt; 0.81) + P(z &lt; -0.81) = 0.418 \) --- fail to reject \(H_0\).</p>
<p><img src="https://user-images.githubusercontent.com/41487483/119316226-ff47f200-bc76-11eb-944a-1c63ee237ebd.png" alt="image" /></p>
<h3><a class="header" href="#22-significance" id="22-significance">2.2 Significance</a></h3>
<h4><a class="header" href="#221-inference-for-other-estimators" id="221-inference-for-other-estimators">2.2.1 Inference for other estimators</a></h4>
<ul>
<li>
<p>point estimates: </p>
<p><em>\(\hat{\theta}\): \(\hat{\theta}_{LMS}\) or (\(\hat{\theta} _{MAP}\)) the concept might be different from MIT statistics course</em></p>
<ol>
<li>
<p>sample mean</p>
</li>
<li>
<p>difference between sample means</p>
</li>
<li>
<p>sample proportion \(\hat{p}\)</p>
</li>
<li>
<p>difference between two proportions</p>
</li>
</ol>
</li>
<li>
<p>two requirements:</p>
<ul>
<li>
<p>nearly normal sampling distribution</p>
</li>
<li>
<p>unbiased estimator assumption: <strong>point estimates</strong> are unbiased, i.e., the sampling distribution of the estimate is centered at the true population parameter it estimates.</p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#22-decision-errors" id="22-decision-errors">2.2 Decision errors</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/125154284-93074c00-e159-11eb-940d-bbec5059b97d.png" alt="image" /></p>
<p><strong>Decrease significance level (\(\alpha\)) decrease Type I error rate</strong></p>
<p>\(P(\text{Type I error}|H_0 \text{ true}) = \alpha\)</p>
<ul>
<li>
<p><strong>Choosing \(\alpha\)</strong></p>
<ul>
<li>
<p>if Type I error is dangerous or costly, choose a small significance level (e.g. 0.01)</p>
</li>
<li>
<p>if Type II error is dangerous or costly, choose a high significance level (e.g. 0.10)</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/125154728-c054f980-e15b-11eb-962c-f200d24dedd0.png" alt="image" /></p>
<p>\(\beta\) depends on the <strong>effect size \(\delta\)</strong> - difference between point estimate and null value.</p>
<h4><a class="header" href="#223-significance-level-vs-confidence-level" id="223-significance-level-vs-confidence-level">2.2.3 Significance level vs. confidence level</a></h4>
<ul>
<li>
<p>complement each other depending on one-sided or two -sided tests</p>
<ul>
<li>two-sided tests: Significance level = 1 - confidence level </li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/125154861-791b3880-e15c-11eb-98d8-55756cf27eaa.png" alt="image" /></p>
<ul>
<li>
<p>one-sided tests: Significance level ≠ confidence level</p>
<p>CL = 1 - 2 x alpha</p>
<p><img src="https://user-images.githubusercontent.com/41487483/125154873-8cc69f00-e15c-11eb-9701-9d1498add575.png" alt="image" /></p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#224-statistical-vs-practical-significance" id="224-statistical-vs-practical-significance">2.2.4 Statistical vs. practical significance</a></h4>
<ul>
<li>
<p>practical significance </p>
<p>Real difference between point estimator and null value are easier to detect with larger samples (effect size)</p>
</li>
<li>
<p>statistical significance </p>
<p>very large samples will result in statistical significance even for tiny differences between sample mean and the null value (effect size), even when the difference is not practically significant. </p>
</li>
</ul>
<h2><a class="header" href="#3-inference-for-comparing-means" id="3-inference-for-comparing-means">3 Inference for Comparing Means</a></h2>
<h3><a class="header" href="#31-t-distribution-and-comparing-two-means" id="31-t-distribution-and-comparing-two-means">3.1 t-distribution and comparing two means</a></h3>
<h4><a class="header" href="#311-t-distribution" id="311-t-distribution">3.1.1 t-distribution</a></h4>
<p>What purpose does a large sample serve?</p>
<p>As long as observations are independent, and the population distribution is not extremely skewed, a large sample would ensure that</p>
<ul>
<li>
<p>the sampling distribution of the mean is nearly normal.</p>
</li>
<li>
<p>the estimate of the standard error is reliable: \(\frac{s}{\sqrt{n}}\)</p>
</li>
</ul>
<p><strong>t-distribution</strong></p>
<ul>
<li>
<p>when <strong>σ</strong> unknown(almost always), use the t-distribution to address the uncertainty of the standard error estimate</p>
</li>
<li>
<p>bell shaped but thicker tails than the normal</p>
<ul>
<li>
<p>observations more likely to fall beyond 2 SDs from the mean</p>
</li>
<li>
<p>extra thick tails helpful for mitigating the effect of a less reliable estimate for the standard error of the sampling distribution</p>
</li>
</ul>
</li>
<li>
<p>always centered as 0</p>
</li>
<li>
<p>only has one parameter <strong>degress of freedom(df)</strong> to determine the thickness of tails: higher df, less thick the tail</p>
<p><em>the normal distribution has two parameters: mean and SD</em></p>
</li>
<li>
<p>for inference on a mean where <strong>σ</strong> unknown, the calculation is the same way as normal distribution </p>
<p>\[
T = \frac{\text{obs - null}}{SE}
\] </p>
<ul>
<li>find p-value (one or two tail area, based on \(H_A\))</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#312-inference-for-a-mean" id="312-inference-for-a-mean">3.1.2 Inference for a mean</a></h4>
<p><a style="color:red">estimating the mean = point estimate ± margin of error </a></p>
<p>\[
\bar{x} \pm t_{df}^*SE_{\bar{x}} 
\\ SE_{\bar{x}} = \frac{s}{\sqrt{n}} 
\]</p>
<p><strong>degrees of freedome for t statistic for inference on one sample mean</strong></p>
<p>\[
df = n - 1<br />
\]</p>
<h4><a class="header" href="#313-inference-for-comparing-two-independent-means" id="313-inference-for-comparing-two-independent-means">3.1.3 Inference for comparing two independent means</a></h4>
<p>estimating the mean = point estimate ± margin of error</p>
<p>\[
(\bar{x_1} - \bar{x_2}) \pm t_{df}^*SE_{(\bar{x_1} - \bar{x_2})} 
\]</p>
<ul>
<li>
<p>SE of difference between two independent means</p>
<p>\[
SE_{(\bar{x_1} - \bar{x_2} )}= \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]</p>
</li>
<li>
<p>DF for t statistics for inference on difference of two means</p>
<p>\[
df = min(n_1-1, n_2-1)
\]</p>
</li>
</ul>
<ul>
<li>
<p>Conditions for inference for comparing two independent means</p>
<ol>
<li>independence: </li>
</ol>
<pre><code>  - within groups: 

      - random sample/assignment

      - if samping without replacement, n &lt; 10% of population

  - between groups: not paired
</code></pre>
<ol start="2">
<li>Sample size/skew: the more skew in the population distributions, the higher the sample size needed.</li>
</ol>
</li>
</ul>
<h4><a class="header" href="#314-inference-for-comparing-two-paried-means" id="314-inference-for-comparing-two-paried-means">3.1.4 Inference for comparing two paried means</a></h4>
<p>When two sets of observations have a special correspondence(not independent), they are said to be <strong>paired</strong>.</p>
<p>Two analyze paired data, it is often useful to look at the difference in outcomes of each pair of observations.</p>
<ul>
<li>
<p>Parameter of interest: \(\mu_{diff}\) - average difference between the reading and writing scores of <strong>all</strong> high school students</p>
</li>
<li>
<p>Point estimate: \(\bar{x}_{diff}\) - average difference between the reading and writing scores of <strong>sampled</strong> high school students</p>
</li>
<li>
<p>\(SE = \frac{s_{diff}}{n}\)</p>
</li>
</ul>
<p><strong>Summary</strong></p>
<ul>
<li>
<p>paired data (2 var.) \(\to\) differences (1 var.)</p>
</li>
<li>
<p>most often: \(H_0:\mu_{diff} = 0\)</p>
</li>
<li>
<p>same individuals: pre-post studies, repeated measures, etc.</p>
</li>
<li>
<p>different but dependent individuals: tiwns, partners, etc.</p>
</li>
</ul>
<h4><a class="header" href="#315-power" id="315-power">3.1.5 Power</a></h4>
<p><img src="https://user-images.githubusercontent.com/41487483/127775746-38903dad-60bf-4393-b8dc-360b78157370.png" alt="image" /></p>
<p><strong>Power</strong> of a test is the probability of correctly rejecting H0, and the probability is \(1-\beta\)</p>
<ul>
<li>Practical problem 1: calculate power for a range of sample sizes and choose target power</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/128233817-c00b3558-5c95-4a10-9e4a-9bfdc107bc85.png" alt="image" /></p>
<ul>
<li>Practical problem 2: calculate required sample size for a desired level of power </li>
</ul>
<p><img src="https://user-images.githubusercontent.com/41487483/127775861-e1c96076-91d9-42a3-9431-9d482ee92888.png" alt="image" /></p>
</br>
<h3><a class="header" href="#32-anova-and-bootstrapping" id="32-anova-and-bootstrapping">3.2 ANOVA and Bootstrapping</a></h3>
<h4><a class="header" href="#321-comparing-more-than-two-means----f-distribution" id="321-comparing-more-than-two-means----f-distribution">3.2.1 Comparing more than two means -- F distribution</a></h4>
<p><strong>ANOVA (analysis of variance) test</strong></p>
<ul>
<li>
<p>\(H_0\): the mean outcome is the same across all categories</p>
</li>
<li>
<p>\(H_A\): at least one pair of means are different from each other</p>
</li>
</ul>
<table><thead><tr><th align="center">t-test</th><th align="center">ANOVA</th></tr></thead><tbody>
<tr><td align="center">compute a test statistic (a ratio)</td><td align="center">Compute a test statistic (a ratio)</td></tr>
<tr><td align="center">\[t = \frac{(\bar{x_1}-\bar{x_2})-(\mu_1-\mu_2)}{SE_{(\bar{x_1}-\bar{x_2})}}\]</td><td align="center">\[F = \frac{\text{variability bet. groups}}{\text{variability within groups}}\]</td></tr>
</tbody></table>
<ul>
<li>
<p>In order to be able to reject \(H_0\), we need a small p-value, which requires a large F statistic.</p>
</li>
<li>
<p>Obtaining a large F statistic requires that the variability between sample means is greater than the variability within the samples.</p>
</li>
</ul>
<h4><a class="header" href="#322-anova" id="322-anova">3.2.2 ANOVA</a></h4>
<ul>
<li>
<p>variability partitioning </p>
<p align="center"><img src="https://user-images.githubusercontent.com/41487483/128079731-462101ec-5e23-4543-8760-e50cf28639ff.png"  width="500" height="180"></p>
</li>
<li>
<p>ANOVA Output</p>
<p><b><div style="text-align: center"> ANOVA Output table</div></b></p>
<p align="center">
  <img src="https://user-images.githubusercontent.com/41487483/128228631-b9e3b806-e2cb-48bf-b005-725ecdb55434.png" width="600" height="150">
  </p>
<ul>
<li>
<p>The first row is about between group variability (<u>Group row</u>) and the second the row is the within group variability (<u>Error row</u>)</p>
</li>
<li>
<p>Sum square error</p>
</li>
</ul>
<pre><code>  - Total: sum of squares total (SST) measures the total variability in the response variable. The caculation is very similar to that of variance except for no dividing by the sample size.

      \\[
          SST = \sum\limits_{i=1}^n (y_i-\bar{y})^2    
      \\]

      \\(y_i\\): value of the response variable for each observation

      \\(\bar{y}\\): grand mean of the response variable

  - Group: sum of squares groups (SSG) measures the variability between groups. &lt;u&gt;Explained variability&lt;/u&gt;: squared deviation of group means from overall mean, weighted by sample size. 

      \\[
          SSG = \sum\limits_{j=1}^k n_j(\bar{y_j}-\bar{y})^2    
      \\]

      \\(n_j\\): number of observations in group *j*

      \\(y_j\\): mean of the response variable for group *j*

      \\(\bar{y}\\): grand mean of the response variable

  - Error: sum of squares error (SSE) measures the variability within groups. &lt;u&gt;Unexplained variability&lt;/u&gt;: unexplained by the group variable due to other reasons

      \\[
          SSE = SST - SSG  
      \\]
</code></pre>
<ul>
<li>
<p>DF: degree of freedom</p>
</li>
<li>
<p>Mean square error: average variability between and within groups, calculated as the total variability (sum of squares) scaled by the associated degrees of freedom.</p>
<ul>
<li>
<p>group: MSG = SSG/DF<sub>G</sub></p>
</li>
<li>
<p>error: MSE = SSE/DF<sub>E</sub></p>
</li>
</ul>
</li>
<li>
<p>F statistics: ratio of the average between group and within group variabilities</p>
<p>\[
F = \frac{MSG}{MSE}<br />
\]</p>
</li>
<li>
<p>Calculate p-value according to F statistics, and remember F always positive we only calculate one-tail.</p>
<ul>
<li>
<p>if p-value is small (less than \(\alpha\)): reject H0</p>
<p>The data provide convincing evidence that at least one pair of population means are different from each other (but we cannot tell which one)</p>
</li>
<li>
<p>if p-value is large (larger than \(\alpha\)): fail to reject H0</p>
<p>The data do not provide convincing evidence that at least one pair of population means are different from each other; the observed difference in sample means are attributable to sampling variability (or chance)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#323-anova-conditions" id="323-anova-conditions">3.2.3 ANOVA conditions</a></h4>
<ol>
<li>
<p>Independence: between groups and within groups</p>
</li>
<li>
<p>Approximate normality: distributions should be nearly normal within each group</p>
</li>
<li>
<p>constant variance: groups should have roughly equal variability </p>
<p><em>side-by-side boxplot is helpful to check constant variance condition</em></p>
</li>
</ol>
<h4><a class="header" href="#324-multiple-comparisons" id="324-multiple-comparisons">3.2.4 Multiple comparisons</a></h4>
<ul>
<li>
<p><strong>Bonferroni correction</strong>: adjust \(\alpha\) by the number of comparison being considered K</p>
<p>\[
K = \frac{k(k-1)}{2} \\
\alpha^* = \alpha/K<br />
\]</p>
</li>
<li>
<p>Pairwise comparisons:</p>
<ul>
<li>
<p>constant variance \(to\) use consistent standard error and degrees of freedom for all tests</p>
</li>
<li>
<p>compare p-values from each test to the modified significance level</p>
</li>
<li>
<p>Standard error for multiple pairwise comparisons:</p>
<p>\[
SE = \sqrt{\frac{MSE}{n_1}+\frac{MSE}{n_2}}
\]</p>
<p>compared to t test between two independent groups \(SE = \sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}\)</p>
</li>
<li>
<p>Degrees of freedom for multiple pairwise comparisons: df = df<sub>E</sub></p>
<p>compared to t test: df = min(n<sub>1</sub> - 1, n<sub>2</sub> - 1)</p>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#325-bootstrapping" id="325-bootstrapping">3.2.5 Bootstrapping</a></h4>
<ul>
<li>
<p><strong>Bootstrapping scheme:</strong></p>
<ol>
<li>
<p>take a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample</p>
</li>
<li>
<p>calculate bootstrap statistic - mean, median, proportion, etc. computed on the bootstrap samples.</p>
</li>
<li>
<p>repeat steps 1 and 2 many times to create a bootstrap distribution - a distribution of bootstrap statistics.</p>
</li>
</ol>
</li>
<li>
<p>calculate confidence interval:</p>
<ol>
<li>
<p>percentile method</p>
</li>
<li>
<p>standard error method</p>
</li>
</ol>
</li>
<li>
<p>limitations</p>
<ul>
<li>
<p>not as rigid conditions as CLT based methods</p>
</li>
<li>
<p>if bootstrap distribution is extremely skewed or sparse, the bootstrap interval might be unreliable</p>
</li>
<li>
<p>A representative sample is still needed - if the sample is biased, the estimates resulting from this sample will also be bias.</p>
</li>
</ul>
</li>
</ul>
<p><strong>Bootstrap vs. sampling distribution</strong></p>
<pre><code>- sampling distribution: created using sampling with replacement from the &lt;u&gt;population&lt;/u&gt;

- Bootstrap distribution: created using sampling with replacement from the &lt;u&gt;sample&lt;/u&gt;

- Both are distributions of sample statistics</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../statistics/statinfer.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../statistics/python.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../statistics/statinfer.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../statistics/python.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
